{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fe2524-5ea0-4561-96f3-dd541648f570",
   "metadata": {},
   "source": [
    "# Setup dependencies / Set up GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb9a70f-dfb3-4e37-b62c-aa3fa6caa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52f1994-2704-4723-94df-b9e45e5462be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b2906a-189d-4d1c-b25e-364ac9ecf880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip list # used to make sure correct version of tensorflow is installed for gpu acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248db512-b6d6-4b1d-b00d-4b9f0a5c7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c243f47-a1a6-47a7-aa8f-58901e35f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8d63e-943d-4db2-8289-5e67bb970006",
   "metadata": {},
   "source": [
    "# 1.0 Load and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f5cd9-df35-42bf-b378-67394075fb5b",
   "metadata": {},
   "source": [
    "# 1.1 import mnist dataset and split into train/test/val (70,15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdb2f5c-6dd6-4c96-bcaf-c837b4463ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c411f13-48dd-440a-b00f-784a35ee79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6ff0e7-e3ce-495a-8b7c-c1a62653a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ed3f0b-66ca-41ba-a69d-7b0b6db07e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd5753-07c5-43b6-a046-bea1b62dd9d1",
   "metadata": {},
   "source": [
    "# 1.2 Visualize data using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66af9102-e9fa-4d94-a3d1-2dd70eab1c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x2800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(ncols = 8, figsize = (28,28))\n",
    "rows = 0\n",
    "for idx,img in enumerate(X_train[:8]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f329c-63ad-4339-ba04-0732c6feffeb",
   "metadata": {},
   "source": [
    "# 1.3 Apply normalization --> all pixels between 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf6122b-bcd4-47cb-a8ce-31562f5587a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "838d65f7-2efb-4cec-b65c-3c8324099181",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a971127-5d5a-4257-b339-9ea7de6a8b45",
   "metadata": {},
   "source": [
    "# 1.4 setup data iterator to batch/prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8f5214-d2e0-452b-83ff-9b644522516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tf.data.Dataset.from_tensor_slices((X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e898a6c4-3779-4776-85c2-69145bf5a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7fd62b-728b-46e1-9b8b-bb42276016e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = df.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd99ca1-70fe-45a4-92ae-93fa281ed767",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102757e6-bfdc-44ca-b79f-2abb0b83e68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a2400-0a42-4727-b6df-1aa45102e3cc",
   "metadata": {},
   "source": [
    "# 1.4 Create train and val data \n",
    "\n",
    "### train size ~ 50k images\n",
    "### val size ~ 10k images\n",
    "### test size ~ 10k images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "597fe351-4073-4c9c-b0dc-469fe997fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1562\n",
    "val_size = len(df) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143cd3e2-c743-4518-9cb7-bca631f6b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.take(train_size)\n",
    "val = df.skip(train_size).take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87379ac2-f473-487a-82c6-f52c8ebb01b2",
   "metadata": {},
   "source": [
    "# 2 Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad30c888-af37-4524-8bcf-162eff239587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c93ff35-dafe-45bb-aa3b-89622f7b6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, MaxPooling2D, BatchNormalization, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "735c6ed9-f192-4cb1-8253-a95e2ff854b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Layer\n",
    "    model.add(Conv2D(16,(3,3),1,activation = \"relu\",input_shape = (28,28,1)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add((ReLU(0.2)))\n",
    "\n",
    "    # Second Layer\n",
    "    model.add(Conv2D(16,(3,3),1,activation = \"relu\",input_shape = (28,28)))\n",
    "    model.add((ReLU(0.2)))\n",
    "\n",
    "    # Third Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation = \"sigmoid\"))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Final layer\n",
    "    model.add(Dense(10,activation = \"softmax\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b22c59d2-baef-4fd4-8268-0a3f090ca7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile('adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be3fbbdd-a266-4711-9911-23e7fd78cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 13, 13, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " re_lu_18 (ReLU)             (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 11, 11, 16)        2320      \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             (None, 11, 11, 16)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               247936    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251,706\n",
      "Trainable params: 251,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850933d3-b1bb-43a0-9ee6-d83f727b6150",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce791b7c-8fe6-4cc3-bee7-54391bc007b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "120a6b70-c6fc-4df2-a8cb-202da2fb03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5559daa-77e3-4c2c-9db3-e2bc83ce6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1562/1562 [==============================] - 11s 4ms/step - loss: 0.3574 - accuracy: 0.9023 - val_loss: 0.1041 - val_accuracy: 0.9731\n",
      "Epoch 2/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.1084 - accuracy: 0.9683 - val_loss: 0.0706 - val_accuracy: 0.9809\n",
      "Epoch 3/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0782 - accuracy: 0.9769 - val_loss: 0.0566 - val_accuracy: 0.9841\n",
      "Epoch 4/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0615 - accuracy: 0.9816 - val_loss: 0.0518 - val_accuracy: 0.9847\n",
      "Epoch 5/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.0448 - val_accuracy: 0.9873\n",
      "Epoch 6/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0455 - val_accuracy: 0.9873\n",
      "Epoch 7/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 0.0422 - val_accuracy: 0.9888\n",
      "Epoch 8/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 9/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0398 - val_accuracy: 0.9877\n",
      "Epoch 11/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0436 - val_accuracy: 0.9876\n",
      "Epoch 12/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0414 - val_accuracy: 0.9884\n",
      "Epoch 13/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
      "Epoch 14/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0413 - val_accuracy: 0.9886\n",
      "Epoch 15/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0451 - val_accuracy: 0.9879\n",
      "Epoch 16/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0441 - val_accuracy: 0.9887\n",
      "Epoch 17/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 18/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0465 - val_accuracy: 0.9880\n",
      "Epoch 19/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0491 - val_accuracy: 0.9875\n",
      "Epoch 20/20\n",
      "1562/1562 [==============================] - 6s 4ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0459 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train,epochs=20,validation_data=val, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da3e25-6c6f-4a81-af79-c77f521dd429",
   "metadata": {},
   "source": [
    "# Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6e7f7b65-7a48-404a-a71a-5ca3d8e93fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fcc4b52-fe0c-4d98-b992-c1b78cbe1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tf.data.Dataset.from_tensor_slices((X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef1a1fe3-e8d0-42a5-9e36-5067a5131bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38dd2433-1cf1-46ba-b381-e1281d0836f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator_test = df_test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "093d4910-7589-4ea8-b10c-f732ee946fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86b0e964-769d-4693-b20a-23f58d6a947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.take(313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "51f97dfe-66b3-4cf7-a05b-34d2c0291b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "[0.0019897951278835535, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "[0.008093206211924553, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "[0.009896855801343918, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5607e-04 - accuracy: 1.0000\n",
      "[0.0005560675053857267, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "[0.01683449186384678, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0632 - accuracy: 0.9688\n",
      "[0.06324878334999084, 0.96875]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "[0.002063431078568101, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.0012650478165596724, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.0013934525195509195, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "[0.0016071107238531113, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.8579e-05 - accuracy: 1.0000\n",
      "[5.857922224095091e-05, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8632e-04 - accuracy: 1.0000\n",
      "[0.0003863207530230284, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "[0.007443268317729235, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "[0.00943335983902216, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.7301e-04 - accuracy: 1.0000\n",
      "[0.0008730110130272806, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0586 - accuracy: 0.9375\n",
      "[0.058595553040504456, 0.9375]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "[0.001987510360777378, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9026e-04 - accuracy: 1.0000\n",
      "[0.00019026231893803924, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7215e-04 - accuracy: 1.0000\n",
      "[0.00017215385742019862, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.0012510484084486961, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.0515e-05 - accuracy: 1.0000\n",
      "[6.051489253877662e-05, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.6054e-05 - accuracy: 1.0000\n",
      "[3.6053657822776586e-05, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9596e-04 - accuracy: 1.0000\n",
      "[0.0002959631965495646, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3236e-05 - accuracy: 1.0000\n",
      "[4.323571192799136e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "[0.009161114692687988, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5193e-05 - accuracy: 1.0000\n",
      "[1.5192663340712897e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.5033e-04 - accuracy: 1.0000\n",
      "[0.00025032609119080007, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.2042e-04 - accuracy: 1.0000\n",
      "[0.0008204217883758247, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1017 - accuracy: 0.9688\n",
      "[0.10166037082672119, 0.96875]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.3833e-05 - accuracy: 1.0000\n",
      "[5.383304596762173e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.5667e-04 - accuracy: 1.0000\n",
      "[0.0009566748049110174, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.4231e-05 - accuracy: 1.0000\n",
      "[7.423139322781935e-05, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "[0.010078650899231434, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "[0.014741516672074795, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[0.0011991281062364578, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.0013349263463169336, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0293e-04 - accuracy: 1.0000\n",
      "[0.0003029268700629473, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2831e-05 - accuracy: 1.0000\n",
      "[4.28306229878217e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "[0.005262535996735096, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "[0.006551733706146479, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "[0.02387971431016922, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.1854e-04 - accuracy: 1.0000\n",
      "[0.00041853816946968436, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "[0.021357379853725433, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "[0.007031708024442196, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6714e-05 - accuracy: 1.0000\n",
      "[2.671368383744266e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.2210e-04 - accuracy: 1.0000\n",
      "[0.00032209872733801603, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4281e-05 - accuracy: 1.0000\n",
      "[3.4280608815606683e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.4065e-04 - accuracy: 1.0000\n",
      "[0.0009406512835994363, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1827e-05 - accuracy: 1.0000\n",
      "[6.182726065162569e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6722e-04 - accuracy: 1.0000\n",
      "[0.00026721885660663247, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "[0.003318550530821085, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4925e-05 - accuracy: 1.0000\n",
      "[3.4924581996165216e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8027e-04 - accuracy: 1.0000\n",
      "[0.0002802696544677019, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.4426e-04 - accuracy: 1.0000\n",
      "[0.0005442604306153953, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.9930e-04 - accuracy: 1.0000\n",
      "[0.0004992971662431955, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "[0.003826727159321308, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0657e-04 - accuracy: 1.0000\n",
      "[0.00010657333768904209, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7157e-04 - accuracy: 1.0000\n",
      "[0.00027157459408044815, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.6868e-05 - accuracy: 1.0000\n",
      "[8.686811634106562e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.8497e-04 - accuracy: 1.0000\n",
      "[0.0006849653436802328, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.8950e-04 - accuracy: 1.0000\n",
      "[0.0005895002977922559, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "[0.0037545496597886086, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "[0.0028100351337343454, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3318e-04 - accuracy: 1.0000\n",
      "[0.00033318487112410367, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "[0.0019356966949999332, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.2837e-05 - accuracy: 1.0000\n",
      "[6.283748371060938e-05, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6102e-06 - accuracy: 1.0000\n",
      "[7.61015735406545e-06, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.3707e-04 - accuracy: 1.0000\n",
      "[0.0007370715611614287, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "[0.0022189656738191843, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "[0.01663457415997982, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2167e-04 - accuracy: 1.0000\n",
      "[0.00012167324894107878, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.4224e-04 - accuracy: 1.0000\n",
      "[0.0005422410322353244, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "[0.0022185570560395718, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1497e-05 - accuracy: 1.0000\n",
      "[2.1496973204193637e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "[0.002465831581503153, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "[0.005402206908911467, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0046e-05 - accuracy: 1.0000\n",
      "[3.004626887559425e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3179e-04 - accuracy: 1.0000\n",
      "[0.00013179158850107342, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.9255e-06 - accuracy: 1.0000\n",
      "[8.925497240852565e-06, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1093 - accuracy: 0.9688\n",
      "[0.10933009535074234, 0.96875]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "[0.004245563875883818, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "[0.0014620512956753373, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1099e-04 - accuracy: 1.0000\n",
      "[0.00021098690922372043, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0536 - accuracy: 0.9688\n",
      "[0.053566981106996536, 0.96875]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.6118e-04 - accuracy: 1.0000\n",
      "[0.00036117580020800233, 1.0]\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "[0.00533649604767561, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "[0.0022426401264965534, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.9835e-05 - accuracy: 1.0000\n",
      "[6.983515049796551e-05, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "[0.004127371124923229, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7271e-04 - accuracy: 1.0000\n",
      "[0.0003727097937371582, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2004e-04 - accuracy: 1.0000\n",
      "[0.00022003818594384938, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.9036e-04 - accuracy: 1.0000\n",
      "[0.0005903640994802117, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.7990e-05 - accuracy: 1.0000\n",
      "[5.799049176857807e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1298e-04 - accuracy: 1.0000\n",
      "[0.00021297993953339756, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0718 - accuracy: 0.9688\n",
      "[0.07176438719034195, 0.96875]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0011495481012389064, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "[0.0019457307644188404, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[0.001220249803736806, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6819e-05 - accuracy: 1.0000\n",
      "[1.6818712538224645e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "[0.002233213046565652, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "[0.0020427419804036617, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0179e-05 - accuracy: 1.0000\n",
      "[2.0178649720037356e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "[0.0014512472553178668, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.3953e-05 - accuracy: 1.0000\n",
      "[9.395319648319855e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.6593e-04 - accuracy: 1.0000\n",
      "[0.0008659277809783816, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "[0.011042876169085503, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.2138e-05 - accuracy: 1.0000\n",
      "[7.213832577690482e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0262e-04 - accuracy: 1.0000\n",
      "[0.0002026247966568917, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "[0.016791513189673424, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.1981e-04 - accuracy: 1.0000\n",
      "[0.0008198136347346008, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0256 - accuracy: 0.9688\n",
      "[0.025569437071681023, 0.96875]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "[0.002675500465556979, 1.0]\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.9171e-04 - accuracy: 1.0000\n",
      "[0.0009917091811075807, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.0013342851307243109, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.5525e-04 - accuracy: 1.0000\n",
      "[0.0002552491787355393, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "[0.013906572014093399, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.5626e-04 - accuracy: 1.0000\n",
      "[0.00045625935308635235, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "[0.016571808606386185, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0724e-04 - accuracy: 1.0000\n",
      "[0.00020724089699797332, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.0013079700293019414, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9812e-05 - accuracy: 1.0000\n",
      "[3.981198096880689e-05, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.1809e-05 - accuracy: 1.0000\n",
      "[7.180882676038891e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8895e-05 - accuracy: 1.0000\n",
      "[4.889455885859206e-05, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8320e-04 - accuracy: 1.0000\n",
      "[0.0003832019283436239, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0010863475035876036, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[0.0011915229260921478, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "[0.0025899577885866165, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.8659e-05 - accuracy: 1.0000\n",
      "[8.86587004060857e-05, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "[0.0015914718387648463, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "[0.0017582856817170978, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0977e-04 - accuracy: 1.0000\n",
      "[0.00010976914200000465, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.1750e-04 - accuracy: 1.0000\n",
      "[0.00041750475065782666, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.7872e-04 - accuracy: 1.0000\n",
      "[0.0006787152378819883, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1382e-04 - accuracy: 1.0000\n",
      "[0.00021381719852797687, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4749e-04 - accuracy: 1.0000\n",
      "[0.0001474879973102361, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2755e-04 - accuracy: 1.0000\n",
      "[0.00042754720197990537, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "[0.003024610923603177, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2502e-04 - accuracy: 1.0000\n",
      "[0.00022501857893075794, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "[0.002352782292291522, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "[0.008660603314638138, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9052e-05 - accuracy: 1.0000\n",
      "[5.905197758693248e-05, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1989e-04 - accuracy: 1.0000\n",
      "[0.00011989283666480333, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4126e-04 - accuracy: 1.0000\n",
      "[0.00024126088828779757, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.0013831775868311524, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "[0.0031726774759590626, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.0014156654942780733, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.3716e-04 - accuracy: 1.0000\n",
      "[0.0007371631800197065, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3299e-04 - accuracy: 1.0000\n",
      "[0.00023298764426726848, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "[0.008871362544596195, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3165e-04 - accuracy: 1.0000\n",
      "[0.00023165310267359018, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0277 - accuracy: 0.9688\n",
      "[0.027691401541233063, 0.96875]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "[0.002341260202229023, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "[0.005544267129153013, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8207e-04 - accuracy: 1.0000\n",
      "[0.00028207077411934733, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0265 - accuracy: 0.9688\n",
      "[0.026487993076443672, 0.96875]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0081e-04 - accuracy: 1.0000\n",
      "[0.000300806132145226, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "[0.005179872736334801, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.0118e-04 - accuracy: 1.0000\n",
      "[0.0006011808291077614, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.2657e-04 - accuracy: 1.0000\n",
      "[0.0009265686967410147, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "[0.0055290041491389275, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6313e-04 - accuracy: 1.0000\n",
      "[0.0007631348562426865, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "[0.0031052192207425833, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.8273e-04 - accuracy: 1.0000\n",
      "[0.00078273203689605, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "[0.004145229235291481, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "[0.002599379513412714, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[0.0011577411787584424, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.6173e-04 - accuracy: 1.0000\n",
      "[0.0005617316346615553, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1499e-04 - accuracy: 1.0000\n",
      "[0.00021499278955161572, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8321e-05 - accuracy: 1.0000\n",
      "[1.8320957678952254e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "[0.008713910356163979, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6081e-04 - accuracy: 1.0000\n",
      "[0.0001608076854608953, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.4534e-04 - accuracy: 1.0000\n",
      "[0.0007453446160070598, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1580e-04 - accuracy: 1.0000\n",
      "[0.00021580496104434133, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "[0.005487644113600254, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.1205e-04 - accuracy: 1.0000\n",
      "[0.0004120540397707373, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.7725e-05 - accuracy: 1.0000\n",
      "[8.772518776822835e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "[0.0014635893749073148, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "[0.008275852538645267, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "[0.0016892942367121577, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "[0.0019026374211534858, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4575e-04 - accuracy: 1.0000\n",
      "[0.0001457531179767102, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1252 - accuracy: 0.9688\n",
      "[0.12519629299640656, 0.96875]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.0908e-04 - accuracy: 1.0000\n",
      "[0.0006090791430324316, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "[0.011377789080142975, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.0013662821147590876, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0468e-05 - accuracy: 1.0000\n",
      "[5.046783189754933e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "[0.0017931907204911113, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "[0.001738707534968853, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4114e-04 - accuracy: 1.0000\n",
      "[0.00014113521319814026, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "[0.00904749520123005, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "[0.01626005209982395, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.2425e-04 - accuracy: 1.0000\n",
      "[0.0007242546416819096, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "[0.004312500823289156, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "[0.01009772252291441, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7304e-04 - accuracy: 1.0000\n",
      "[0.00017303958884440362, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "[0.013297421857714653, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5819e-04 - accuracy: 1.0000\n",
      "[0.0002581884618848562, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3912e-04 - accuracy: 1.0000\n",
      "[0.00023912129108794034, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "[0.0023699880111962557, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.4170e-04 - accuracy: 1.0000\n",
      "[0.0005416974308900535, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "[0.0024061999283730984, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0372 - accuracy: 0.9688\n",
      "[0.037240322679281235, 0.96875]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0699e-04 - accuracy: 1.0000\n",
      "[0.0005069899489171803, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "[0.0017824199749156833, 1.0]\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.5723e-05 - accuracy: 1.0000\n",
      "[5.572311783907935e-05, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0180e-04 - accuracy: 1.0000\n",
      "[0.0005018016672693193, 1.0]\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "[0.004347632639110088, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6713e-05 - accuracy: 1.0000\n",
      "[7.67134188208729e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "[0.002232296857982874, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "[0.006405200343579054, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5476e-04 - accuracy: 1.0000\n",
      "[0.00015475961845368147, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8683e-05 - accuracy: 1.0000\n",
      "[5.868332664249465e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.1687e-04 - accuracy: 1.0000\n",
      "[0.00041686627082526684, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0011005374835804105, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "[0.008685293607413769, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "[0.018774043768644333, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.001444149063900113, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3592e-04 - accuracy: 1.0000\n",
      "[0.0001359176094410941, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0309e-04 - accuracy: 1.0000\n",
      "[0.00040308813913725317, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0011002039536833763, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.7032e-05 - accuracy: 1.0000\n",
      "[8.703228377271444e-05, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "[0.003498184960335493, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.4867e-05 - accuracy: 1.0000\n",
      "[4.4867094402434304e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8443e-04 - accuracy: 1.0000\n",
      "[0.0001844304642872885, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[0.0014454529155045748, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "[0.0014935543294996023, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9322e-04 - accuracy: 1.0000\n",
      "[0.0002932163479272276, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "[0.017566213384270668, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6785e-04 - accuracy: 1.0000\n",
      "[0.00026784685906022787, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.9574e-04 - accuracy: 1.0000\n",
      "[0.0007957395864650607, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.9476e-04 - accuracy: 1.0000\n",
      "[0.0004947598790749907, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.4906e-05 - accuracy: 1.0000\n",
      "[7.490648567909375e-05, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6986e-04 - accuracy: 1.0000\n",
      "[0.00026986224111169577, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2004e-04 - accuracy: 1.0000\n",
      "[0.000120040203910321, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0411e-04 - accuracy: 1.0000\n",
      "[0.00020411433069966733, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "[0.014628080651164055, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4039e-05 - accuracy: 1.0000\n",
      "[6.403888983186334e-05, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "[0.0019229245372116566, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "[0.0030983055476099253, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.9340e-05 - accuracy: 1.0000\n",
      "[5.934031287324615e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.9108e-05 - accuracy: 1.0000\n",
      "[7.910848216852173e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "[0.0011809221468865871, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.7382e-04 - accuracy: 1.0000\n",
      "[0.0009738185908645391, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.4575e-04 - accuracy: 1.0000\n",
      "[0.0006457458948716521, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "[0.003083030693233013, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "[0.014667198061943054, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "[0.006138075143098831, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4115e-04 - accuracy: 1.0000\n",
      "[0.0004411482368595898, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.6173e-04 - accuracy: 1.0000\n",
      "[0.0003617306938394904, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.0061e-04 - accuracy: 1.0000\n",
      "[0.0005006121355108917, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "[0.0015471610240638256, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9884e-04 - accuracy: 1.0000\n",
      "[0.0001988392905332148, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.7561e-04 - accuracy: 1.0000\n",
      "[0.0004756117705255747, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "[0.0018257859628647566, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7500e-04 - accuracy: 1.0000\n",
      "[0.00027500485884957016, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.4448e-05 - accuracy: 1.0000\n",
      "[8.44479727675207e-05, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "[0.026488332077860832, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.5111e-05 - accuracy: 1.0000\n",
      "[8.511119085596874e-05, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "[0.005167379043996334, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "[0.018933147192001343, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "[0.007390228100121021, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5906e-05 - accuracy: 1.0000\n",
      "[1.5906236512819305e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "[0.005617106333374977, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9364e-04 - accuracy: 1.0000\n",
      "[0.00029363835346885026, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.7489e-04 - accuracy: 1.0000\n",
      "[0.0006748936139047146, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.6790e-04 - accuracy: 1.0000\n",
      "[0.0005679046153090894, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.9198e-05 - accuracy: 1.0000\n",
      "[9.919796139001846e-05, 1.0]\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4873e-04 - accuracy: 1.0000\n",
      "[0.0002487261954229325, 1.0]\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4719e-05 - accuracy: 1.0000\n",
      "[5.471881740959361e-05, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "[0.008928348310291767, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "[0.014326415956020355, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "[0.001264597987756133, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "[0.022785503417253494, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "[0.01382325030863285, 1.0]\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "[0.02076943777501583, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1107e-04 - accuracy: 1.0000\n",
      "[0.0005110650090500712, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "[0.0043729557655751705, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "[0.003252541646361351, 1.0]\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "[0.005027119070291519, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "[0.0028102940414100885, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "[0.004033792298287153, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "[0.005617992486804724, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.6897e-05 - accuracy: 1.0000\n",
      "[3.689700679387897e-05, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "[0.0018265765393152833, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "[0.0019647623412311077, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.0478e-04 - accuracy: 1.0000\n",
      "[0.0002047791931545362, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8642e-04 - accuracy: 1.0000\n",
      "[0.00028642365941777825, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.2206e-05 - accuracy: 1.0000\n",
      "[7.220643601613119e-05, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "[0.005638116970658302, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.3584e-04 - accuracy: 1.0000\n",
      "[0.0005358405760489404, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.7634e-04 - accuracy: 1.0000\n",
      "[0.0005763423396274447, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.5869e-04 - accuracy: 1.0000\n",
      "[0.00045869292807765305, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0010893490398302674, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "[0.015079998411238194, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "[0.011746179312467575, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "[0.01830674149096012, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0329e-04 - accuracy: 1.0000\n",
      "[0.00010328826465411112, 1.0]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "[0.0033233161084353924, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.0978e-04 - accuracy: 1.0000\n",
      "[0.0006097794394008815, 1.0]\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7082e-04 - accuracy: 1.0000\n",
      "[0.00027082019369117916, 1.0]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.5295e-04 - accuracy: 1.0000\n",
      "[0.0007529527647420764, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "[0.004880822263658047, 1.0]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2041e-04 - accuracy: 1.0000\n",
      "[0.00022041279589757323, 1.0]\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4767e-04 - accuracy: 1.0000\n",
      "[0.00014767116226721555, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1402e-05 - accuracy: 1.0000\n",
      "[3.140215267194435e-05, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "[0.00173421751242131, 1.0]\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.3452e-05 - accuracy: 1.0000\n",
      "[8.34524689707905e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.1486e-06 - accuracy: 1.0000\n",
      "[7.148599252104759e-06, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6390e-05 - accuracy: 1.0000\n",
      "[2.6390416678623296e-05, 1.0]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.7172e-07 - accuracy: 1.0000\n",
      "[8.717156561033335e-07, 1.0]\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "[0.007285946048796177, 1.0]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "[0.0036958041600883007, 1.0]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "[0.0011108322069048882, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X,y = batch\n",
    "    print(model.evaluate(X,y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14b66340-88ce-4615-8de1-10e0768369da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CNN_model_of_184.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a24e2-931d-45a3-872d-6a9ea60a7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ACCELERATION",
   "language": "python",
   "name": "gpu_acceleration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
